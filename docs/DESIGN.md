# ML Security Papers - Design Document

*Goal: The best ML Security Research Website on the planet*

---

## Table of Contents

1. [Users & Needs](#users--needs)
2. [Data Architecture](#data-architecture)
3. [Pipeline Design](#pipeline-design)
4. [Classification System](#classification-system)
5. [Website Features](#website-features)
6. [LLM Prompt Design](#llm-prompt-design)
7. [API & Data Sources](#api--data-sources)
8. [Open Questions](#open-questions)

---

## Users & Needs

### Target Users

| User Type | Primary Questions |
|-----------|-------------------|
| **Security Researchers** | What attacks exist against LLMs? What defenses work? What's state of the art? |
| **ML Engineers** | Is my model vulnerable? How do I defend against X? What should I test? |
| **Red Teamers / Pentesters** | How do I attack this ML system? What tools exist? Show me PoC code |
| **Students / Newcomers** | Where do I start? What are seminal papers? What's hot right now? |
| **Policy / Compliance** | What risks exist? How do I map to OWASP? What should audits require? |

### User Needs

**Discovery:**
- What papers exist on topic X?
- What's new this month?
- What's trending / highly cited?
- What did this research group publish?
- Papers similar to this one?

**Understanding:**
- Explain this attack simply
- How does this defense work?
- What's the relationship between papers?
- What's the timeline of this research area?
- Who are the key researchers?

**Action:**
- Give me the PDF
- Show me the code
- How do I cite this?
- What should I read next?
- How do I reproduce this?

---

## Data Architecture

### Paper Data Model

```yaml
Paper:
  # === Identity (from S2) ===
  s2_paper_id: string           # Primary key, stable
  title: string

  # === Content ===
  tldr: string                  # S2 AI-generated summary
  abstract: string              # Full abstract
  eli5: string | null           # Optional: LLM-generated simple explanation

  # === Metadata (from S2) ===
  authors: [Author]
  year: int
  venue: string
  venue_type: conference | journal | preprint | workshop
  fields_of_study: [string]     # S2's categorization
  publication_types: [string]   # S2's paper type
  external_ids:                 # Cross-references
    DOI: string
    ArXiv: string
    DBLP: string
    PMID: string

  # === Metrics (from S2, updated periodically) ===
  citation_count: int
  influential_citation_count: int
  reference_count: int
  trending_score: float         # Calculated: recent citations / age
  metrics_updated_at: timestamp

  # === Resources ===
  pdf_url: string | null        # Open access PDF
  code_url: string | null       # GitHub, etc. (from PapersWithCode?)

  # === Our Classification (multi-label) ===
  owasp_labels: [string]        # [ML01, ML02, ...] - 1 to 3 labels
  paper_type: attack | defense | survey | benchmark | tool | theoretical
  domains: [string]             # [nlp, vision, audio, tabular, multimodal, ...]
  model_types: [string]         # [llm, cnn, transformer, diffusion, ...]
  assets_targeted: [string]     # [training-data, model-weights, api, embeddings, ...]
  tags: [string]                # Free-form tags

  classification_reasoning: string  # LLM's explanation
  classification_confidence: HIGH | LOW
  classified_at: timestamp

  # === Graph / Relationships ===
  depth: int                    # 0 = seed, 1 = cited by seed, etc.
  source: seed | citation | reference | discovery
  discovered_via: string | null # s2_paper_id of parent paper
  related_papers: [string]      # Computed or from S2

  # === Curation (manual) ===
  is_seminal: bool              # Foundational paper
  is_featured: bool             # Editor's pick
  collections: [string]         # "must-read", "best-2024", etc.

  # === Pipeline Status ===
  status: title_only | resolved | fetched | classified | expanded | discarded
```

### Tag Taxonomy (Controlled Vocabulary)

```yaml
domain:
  - nlp
  - vision
  - audio
  - tabular
  - multimodal
  - reinforcement-learning
  - federated-learning
  - generative

model_type:
  - llm
  - cnn
  - transformer
  - diffusion
  - gan
  - rnn
  - graph-neural-network

attack_vector:
  - adversarial-perturbation
  - backdoor
  - trojan
  - prompt-injection
  - jailbreak
  - data-extraction
  - membership-query
  - model-query

paper_type:
  - attack
  - defense
  - survey
  - benchmark
  - tool
  - theoretical

asset_targeted:
  - training-data
  - model-weights
  - model-api
  - predictions
  - embeddings
  - gradients
```

---

## Pipeline Design

### Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           SEED SOURCE                                    â”‚
â”‚                  Awesome-ML-SP-Papers (~450 titles)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 1: RESOLVE                                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚
â”‚  Endpoint: S2 /paper/search/match                                       â”‚
â”‚  Input:    title string                                                 â”‚
â”‚  Output:   s2_paper_id                                                  â”‚
â”‚  Rate:     1/sec = 450 titles in ~8 minutes                            â”‚
â”‚                                                                          â”‚
â”‚  Status: title_only â†’ resolved                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 2: FETCH                                                          â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚
â”‚  Endpoint: S2 /paper/batch (up to 500 per request!)                     â”‚
â”‚  Input:    [s2_paper_id, ...]                                           â”‚
â”‚  Output:   Full metadata for all papers                                 â”‚
â”‚  Rate:     1 request for 500 papers                                     â”‚
â”‚                                                                          â”‚
â”‚  Fields: paperId, title, tldr, abstract, venue, year,                   â”‚
â”‚          fieldsOfStudy, s2FieldsOfStudy, publicationTypes,              â”‚
â”‚          citationCount, influentialCitationCount, referenceCount,       â”‚
â”‚          openAccessPdf, externalIds, authors                            â”‚
â”‚                                                                          â”‚
â”‚  Status: resolved â†’ fetched                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 3: CLASSIFY                                                       â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚
â”‚  Provider: Cerebras (or fallback: Groq, Google)                         â”‚
â”‚  Input:    Full paper context (title, tldr, abstract, venue, fields)    â”‚
â”‚  Output:   Multi-label classification + tags + reasoning                â”‚
â”‚  Rate:     Limited by LLM provider                                      â”‚
â”‚                                                                          â”‚
â”‚  Status: fetched â†’ classified | discarded                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 4: EXPAND (depth-limited BFS)                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚
â”‚  Endpoints: S2 /paper/{id}/citations, /paper/{id}/references            â”‚
â”‚  Input:    Classified papers (ML01-ML10 only, not NONE)                 â”‚
â”‚  Output:   New s2_paper_ids â†’ feed back to PHASE 2                      â”‚
â”‚  Rate:     1/sec per paper                                              â”‚
â”‚                                                                          â”‚
â”‚  Rules:                                                                  â”‚
â”‚    - Only expand papers classified as ML01-ML10                         â”‚
â”‚    - Max depth from seed (e.g., depth â‰¤ 2)                              â”‚
â”‚    - Skip papers already in system                                      â”‚
â”‚                                                                          â”‚
â”‚  Status: classified â†’ expanded                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PHASE 5: EXPORT                                                         â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                       â”‚
â”‚  Output:   Website JSON files                                           â”‚
â”‚  Sorting:  By influentialCitationCount (quality ranking)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Automated Jobs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  JOB: UPDATE_METRICS (weekly)                                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                           â”‚
â”‚  Endpoint: S2 /paper/batch                                              â”‚
â”‚  Purpose:  Refresh citationCount, influentialCitationCount              â”‚
â”‚  Why:      Citation counts change over time                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  JOB: DISCOVER (daily)                                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                   â”‚
â”‚  Endpoint: S2 /paper/{id}/citations                                     â”‚
â”‚  Purpose:  Find NEW papers citing our classified papers                 â”‚
â”‚  Filter:   Only papers from last N days                                 â”‚
â”‚  Output:   New s2_paper_ids â†’ PHASE 2 â†’ PHASE 3                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Rate Limit Math

```
S2 API: 1 request/second with API key = 86,400 requests/day

SEEDS (~450 papers):
  Phase 1 (Resolve):  450 requests = ~8 minutes
  Phase 2 (Fetch):    1 batch request = ~1 second
  Phase 3 (Classify): 450 papers = depends on LLM rate limits
  Phase 4 (Expand):   450 papers Ã— 2 (citations + refs) = ~15 minutes

DAILY DISCOVER:
  Check 500 papers for new citations = ~17 minutes

WEEKLY UPDATE:
  Refresh metrics for 2000 papers = 4 batch requests = ~4 seconds
```

---

## Classification System

### Multi-Label + Tags Approach

Papers can have:
1. **1-3 OWASP labels** (ML01-ML10) - formal taxonomy
2. **1 paper type** (attack/defense/survey/etc)
3. **Multiple domain tags** (nlp, vision, etc)
4. **Multiple model tags** (llm, cnn, etc)
5. **Multiple free-form tags**

### OWASP ML Top 10 Categories

```
ML01 - INPUT MANIPULATION ATTACK
  Adversarial examples that fool models at INFERENCE time.
  âœ“ adversarial examples, evasion, perturbations, prompt injection, jailbreaking
  âœ— attacks on training data (ML02)

ML02 - DATA POISONING ATTACK
  Corrupting TRAINING DATA to make models learn wrong behavior.
  âœ“ backdoor attacks, trojans, label flipping, clean-label attacks
  âœ— manipulating model weights directly (ML10)

ML03 - MODEL INVERSION ATTACK
  RECONSTRUCTING sensitive training data by querying the model.
  âœ“ attribute inference, training data reconstruction, property inference
  âœ— just determining if data was in training set (ML04)

ML04 - MEMBERSHIP INFERENCE ATTACK
  Determining WHETHER a specific record was in the training set.
  âœ“ membership inference, privacy auditing
  âœ— reconstructing the actual data (ML03)

ML05 - MODEL THEFT
  Stealing the MODEL ITSELF - parameters, architecture, functionality.
  âœ“ model extraction, model stealing, knowledge distillation attacks
  âœ— stealing training data (ML03/ML04)

ML06 - AI SUPPLY CHAIN ATTACKS
  Attacking the ML ECOSYSTEM - packages, platforms, model hubs.
  âœ“ malicious packages, compromised pre-trained models, MLOps attacks
  âœ— attacks on the model itself (other categories)

ML07 - TRANSFER LEARNING ATTACK
  Exploiting TRANSFER LEARNING to inject malicious behavior.
  âœ“ backdoored foundation models, malicious fine-tuning
  âœ— general backdoors not via transfer learning (ML02)

ML08 - MODEL SKEWING
  Manipulating FEEDBACK LOOPS in continuously learning systems.
  âœ“ feedback loop attacks, online learning manipulation
  âœ— one-time training data poisoning (ML02)

ML09 - OUTPUT INTEGRITY ATTACK
  Tampering with model OUTPUTS after prediction.
  âœ“ prediction tampering, result manipulation, MITM on inference
  âœ— manipulating inputs (ML01)

ML10 - MODEL POISONING
  Directly manipulating MODEL PARAMETERS/WEIGHTS.
  âœ“ weight manipulation, neural trojan insertion into weights
  âœ— poisoning via training data (ML02)

NONE - NOT ML SECURITY
  âœ“ General ML, using AI FOR security, traditional security
```

### Example Classifications

```yaml
Paper: "BadNets: Identifying Vulnerabilities in ML Model Supply Chain"
owasp_labels: [ML02, ML06]
paper_type: attack
domains: [vision]
model_types: [cnn]
tags: [backdoor, trojan, pre-trained-models]
reasoning: "Backdoor attack (ML02) targeting the model supply chain (ML06)"

Paper: "Extracting Training Data from Large Language Models"
owasp_labels: [ML03]
paper_type: attack
domains: [nlp]
model_types: [llm]
tags: [memorization, privacy, gpt]
reasoning: "Model inversion attack extracting training data from LLMs"

Paper: "SoK: Machine Learning Security"
owasp_labels: [ML01, ML02, ML03, ML04, ML05]
paper_type: survey
domains: [vision, nlp]
model_types: [cnn, transformer]
tags: [systematization, taxonomy]
reasoning: "Comprehensive survey covering multiple attack categories"
```

---

## Website Features

### Navigation Structure

```
BY CATEGORY (OWASP ML Top 10):
â”œâ”€â”€ ML01 Input Manipulation
â”œâ”€â”€ ML02 Data Poisoning
â”œâ”€â”€ ... (all 10 categories)
â””â”€â”€ Cross-category view

BY TYPE:
â”œâ”€â”€ Attacks
â”œâ”€â”€ Defenses
â”œâ”€â”€ Surveys & SoKs
â”œâ”€â”€ Benchmarks
â””â”€â”€ Tools

BY DOMAIN:
â”œâ”€â”€ NLP / LLMs
â”œâ”€â”€ Computer Vision
â”œâ”€â”€ Audio / Speech
â”œâ”€â”€ Multimodal
â””â”€â”€ Federated Learning

BY TIME:
â”œâ”€â”€ This week / month / year
â”œâ”€â”€ Trending (recent + growing citations)
â”œâ”€â”€ Classics (pre-2020, highly cited)
â””â”€â”€ Timeline view
```

### Rich Filtering UI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Search: [                                        ] [ğŸ”]        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Categories: [Ã—ML01] [Ã—ML02] [ML03] [ML04] ...    â† toggle     â”‚
â”‚ Type:       [Ã—Attack] [Defense] [Survey] [Tool]               â”‚
â”‚ Domain:     [Ã—NLP] [Vision] [Audio] [All]                     â”‚
â”‚ Model:      [Ã—LLM] [Transformer] [CNN] [All]                  â”‚
â”‚ Year:       [2020]â”€â”€â”€â”€â—â”€â”€â”€â”€[2026]                â† slider     â”‚
â”‚ Citations:  [0]â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€[1000+]              â† slider     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Paper Card Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Extracting Training Data from Large Language Models             â”‚
â”‚ Carlini, TramÃ¨r, Wallace, et al.                               â”‚
â”‚ USENIX Security 2021                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ”¥ 892 citations (127 influential)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [ML03 Model Inversion]                        â† OWASP labels   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ #LLM #GPT-2 #memorization #privacy #attack   â† tags            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TLDR: We demonstrate that large language models memorize and   â”‚
â”‚ emit training data, including PII, code, and URLs...           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [ğŸ“„ PDF] [ğŸ’» Code] [ğŸ“š Cite] [ğŸ”— S2] [Similar Papers]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Category Landing Pages

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ML03: MODEL INVERSION ATTACK                                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                  â•‘
â•‘  WHAT IS IT?                                                    â•‘
â•‘  Attackers reconstruct sensitive training data by querying      â•‘
â•‘  the model. They reverse-engineer private information.          â•‘
â•‘                                                                  â•‘
â•‘  REAL-WORLD IMPACT:                                             â•‘
â•‘  â€¢ Facial recognition models leak faces                         â•‘
â•‘  â€¢ Medical models leak patient data                             â•‘
â•‘  â€¢ LLMs leak training text, PII, code                          â•‘
â•‘                                                                  â•‘
â•‘  SEMINAL PAPERS:              TOP DEFENSES:                     â•‘
â•‘  â€¢ Fredrikson 2015            â€¢ Differential Privacy            â•‘
â•‘  â€¢ Carlini 2021 (LLMs)        â€¢ Output perturbation            â•‘
â•‘                                                                  â•‘
â•‘  [View all 89 papers â†’]                                         â•‘
â•‘                                                                  â•‘
â•‘  RELATED: [ML04 Membership Inference] [ML05 Model Theft]        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Visualizations

**Attack Landscape Graph:**
- Nodes = categories (size = paper count)
- Edges = papers with multiple labels

**Timeline View:**
- Papers plotted by year
- Highlight seminal papers
- Show research trends

**Trends Charts:**
- Papers per category per year
- Attack vs Defense ratio over time
- Domain distribution evolution
- Citation growth over time

### Learning Paths

```
ğŸ“ NEW TO ML SECURITY?

Start Here:
1. "SoK: Machine Learning Security" (overview)
2. "Explaining and Harnessing Adversarial Examples" (foundational)
3. "Towards Evaluating the Robustness of Neural Networks" (attacks)

Then explore by interest:
â”œâ”€â”€ Want to attack LLMs? â†’ [LLM Attack Path]
â”œâ”€â”€ Want to defend models? â†’ [Defense Path]
â”œâ”€â”€ Interested in privacy? â†’ [Privacy Path]
â””â”€â”€ Building secure ML? â†’ [MLSecOps Path]
```

### Curated Collections

- "Must-read papers for ML security"
- "Best papers of 2024"
- "Papers with code"
- "Industry-relevant attacks"
- "Beginner-friendly explanations"
- Community-submitted collections

### Insights Dashboard

- "X% of papers are attacks, Y% are defenses"
- "LLM security grew 400% in 2023"
- "Most under-researched area: ML08 Model Skewing"
- "Top venues: USENIX, S&P, NeurIPS"
- Auto-generated monthly digest

---

## LLM Prompt Design

### Prompt Template Location

```
configs/
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ classification.md     # Full prompt template
â”œâ”€â”€ categories.yaml           # OWASP category definitions
â””â”€â”€ tags.yaml                 # Controlled vocabulary
```

### Classification Prompt

See `configs/prompts/classification.md` for full prompt.

**Input to LLM:**
```
TITLE: {title}
TLDR: {tldr}
ABSTRACT: {abstract}
VENUE: {venue}
YEAR: {year}
FIELDS OF STUDY: {fields_of_study}
PUBLICATION TYPE: {publication_types}
```

**Expected Output:**
```json
{
  "owasp_labels": ["ML02", "ML07"],
  "paper_type": "attack",
  "domains": ["nlp"],
  "model_types": ["llm", "transformer"],
  "tags": ["backdoor", "transfer-learning", "fine-tuning"],
  "confidence": "HIGH",
  "reasoning": "Paper presents backdoor attack (ML02) that exploits transfer learning pipeline (ML07), targeting transformer-based LLMs."
}
```

---

## API & Data Sources

### Semantic Scholar API

**Base URL:** `https://api.semanticscholar.org/graph/v1`

**Key Endpoints:**
| Endpoint | Purpose | Rate |
|----------|---------|------|
| `/paper/search/match` | Find paper by title | 1/sec |
| `/paper/batch` | Get up to 500 papers | 1/sec |
| `/paper/{id}` | Get single paper | 1/sec |
| `/paper/{id}/citations` | Papers citing this | 1/sec |
| `/paper/{id}/references` | Papers this cites | 1/sec |

**Available Fields:**
- paperId, corpusId, externalIds
- title, abstract, tldr
- venue, year, publicationDate
- authors, fieldsOfStudy, publicationTypes
- citationCount, influentialCitationCount, referenceCount
- openAccessPdf, url

### LLM Providers

| Provider | Model | Rate Limit | Cost |
|----------|-------|------------|------|
| Cerebras | llama-3.3-70b | Free tier limited | Free |
| Groq | llama-3.3-70b | 30 req/min? | Free |
| Google | gemini-2.0-flash | Daily quota | Free |

---

## Open Questions

### Classification
- [ ] Min/max OWASP labels per paper? (suggest: 1-3)
- [ ] Controlled vocab for tags, or free-form + normalize?
- [ ] Re-classify if paper gets influential citations later?
- [ ] Human review for low-confidence classifications?

### Website
- [ ] How to count papers per category with multi-label?
- [ ] Show "primary" label or treat all equally?
- [ ] User accounts for saving papers / collections?
- [ ] API for programmatic access?

### Data
- [ ] Include preprints or only peer-reviewed?
- [ ] Minimum citation threshold for expansion?
- [ ] How far to expand graph? (depth limit)
- [ ] Include non-English papers?

### Operations
- [ ] How often to re-classify with improved prompts?
- [ ] Backup / versioning strategy for data?
- [ ] Monitoring for API failures?

---

## File Structure

```
ml-security-papers/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ prompts/
â”‚   â”‚   â””â”€â”€ classification.md
â”‚   â”œâ”€â”€ categories.yaml
â”‚   â””â”€â”€ tags.yaml
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ pipeline/
â”‚       â”œâ”€â”€ resolve.py      # title â†’ s2_paper_id
â”‚       â”œâ”€â”€ fetch.py        # s2_paper_id â†’ full metadata
â”‚       â”œâ”€â”€ classify.py     # metadata â†’ labels + tags
â”‚       â”œâ”€â”€ expand.py       # get citations/references
â”‚       â”œâ”€â”€ discover.py     # find new papers daily
â”‚       â”œâ”€â”€ update.py       # refresh citation counts
â”‚       â”œâ”€â”€ export.py       # generate website JSON
â”‚       â””â”€â”€ state.py        # paper state management
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ paper_state.json    # all papers + status
â”‚   â”œâ”€â”€ seeds.json          # original seed titles
â”‚   â”œâ”€â”€ manifest.json       # website metadata
â”‚   â””â”€â”€ papers/
â”‚       â”œâ”€â”€ ml01.json
â”‚       â””â”€â”€ ...
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ css/
â”‚   â””â”€â”€ js/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ DESIGN.md           # this file
â”‚   â””â”€â”€ ARCHITECTURE.md
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ update-papers.yml
```

---

## What Makes It "Best"

1. **COMPREHENSIVE** - Every ML security paper, not just famous ones
2. **ORGANIZED** - OWASP taxonomy + rich multi-label tags
3. **DISCOVERABLE** - Search, filter, visualize, explore
4. **ACTIONABLE** - PDFs, code, citations ready
5. **CURRENT** - Daily updates, trending papers
6. **EDUCATIONAL** - Learning paths, explanations, curated collections
7. **QUALITY-RANKED** - Influential citations, not just counts
8. **BEAUTIFUL** - Clean, fast, delightful UX
