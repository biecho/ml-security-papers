# Configuration for paper filtering - ML05: Model Theft
# OWASP Machine Learning Security Top 10

domain:
  name: "model_theft"
  owasp_id: "ML05"
  owasp_name: "Model Theft"
  description: "Research on stealing, extracting, or cloning machine learning models"
  short_description: "Techniques to steal or extract ML models without authorization"

# High-quality keywords that strongly indicate relevant papers
high_quality_keywords:
  - "model extraction attack"
  - "model stealing attack"
  - "knockoff net"
  - "knockoff nets"
  - "copycat CNN"
  - "copycat model"
  - "clone model"
  - "cloning attack"

# Core keywords that may indicate relevant papers
core_keywords:
  - "model extraction"
  - "model stealing"
  - "steal model"
  - "extract model"
  - "stealing model"
  - "extracting model"
  - "cloning model"
  - "functionality stealing"
  - "black-box model stealing"
  - "query-based model extraction"
  - "API model extraction"

# Defense-related keywords (still relevant to the domain)
defense_keywords:
  - "model extraction defense"
  - "model stealing defense"
  - "prevent model extraction"
  - "prevent model stealing"

# Keywords known to cause false positives - should be avoided
problematic_keywords:
  - "electromagnetic analysis"
  - "electromagnetic neural network"
  - "power analysis neural network"
  - "cache attack DNN"
  - "timing attack neural network"
  - "DNN weights leakage"
  - "imitation attack"
  - "side-channel neural network"

# Terms that must appear in abstract for a paper to be considered relevant
required_abstract_terms:
  - "model stealing"
  - "model extraction"
  - "steal model"
  - "extract model"
  - "clone model"
  - "knockoff"
  - "copycat"

# Signals that indicate the paper is about something else
exclusion_signals:
  prompt_stealing:
    - "prompt stealing"
    - "prompt template"
    - "text-to-image"
  link_stealing:
    - "link stealing"
    - "graph structure"
  data_stealing:
    - "stealing input data"
    - "stealing privacy"
    - "data privacy"
  membership_inference:
    - "membership inference"
  adversarial_examples:
    - "adversarial example"
    - "adversarial perturbation"

# Topics that may mention the domain but are primarily about something else
other_topics:
  watermarking:
    - "watermark"
    - "fingerprint"
  backdoor:
    - "backdoor attack"
    - "trojan attack"
    - "poisoning attack"
  privacy:
    - "differential privacy"
    - "privacy-preserving"
    - "data privacy"
  federated_learning:
    - "federated learning"

# Filtering thresholds and rules
filtering_rules:
  # Minimum number of core term mentions for relevance
  min_term_mentions: 1

  # If watermarking is mentioned this many times and model stealing only few times, likely off-topic
  watermark_dominance_threshold: 3

  # If other topic count is this multiple of model stealing count, likely off-topic
  topic_dominance_ratio: 2.0

  # Number of characters to check for context when verifying compound terms
  context_window: 50

  # Number of characters from start of abstract to check for primary focus
  first_paragraph_length: 300
